{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 647/647 [00:00<00:00, 184kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to C:/Users/DELL/.cache/huggingface/datasets/Tuana___parquet/Tuana--presidents-a7468d21c15276e0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 5.00M/5.00M [00:03<00:00, 1.55MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:06<00:00,  6.40s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 37.04it/s]\n",
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to C:/Users/DELL/.cache/huggingface/datasets/Tuana___parquet/Tuana--presidents-a7468d21c15276e0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating BM25 representation...: 100%|██████████| 5400/5400 [00:01<00:00, 3030.45 docs/s]\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from datasets import load_dataset\n",
    "\n",
    "remote_dataset = load_dataset('Tuana/presidents', split=\"train\")\n",
    "\n",
    "document_store = InMemoryDocumentStore(use_bm25=True)\n",
    "document_store.write_documents(remote_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 94.3kB/s]\n",
      "Downloading (…)16ebc/.gitattributes: 100%|██████████| 737/737 [00:00<00:00, 1.01MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 188kB/s]\n",
      "Downloading (…)b6b5d16ebc/README.md: 100%|██████████| 8.65k/8.65k [00:00<00:00, 8.63MB/s]\n",
      "Downloading (…)b5d16ebc/config.json: 100%|██████████| 571/571 [00:00<00:00, 508kB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 116kB/s]\n",
      "Downloading (…)ebc/data_config.json: 100%|██████████| 25.5k/25.5k [00:00<00:00, 12.7MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [02:13<00:00, 3.28MB/s] \n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 52.9kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 120kB/s]\n",
      "Downloading (…)16ebc/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 648kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 363/363 [00:00<?, ?B/s] \n",
      "Downloading (…)6ebc/train_script.py: 100%|██████████| 13.9k/13.9k [00:00<00:00, 3.48MB/s]\n",
      "Downloading (…)b6b5d16ebc/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 3.73MB/s]\n",
      "Downloading (…)5d16ebc/modules.json: 100%|██████████| 229/229 [00:00<00:00, 118kB/s]\n",
      "c:\\Users\\DELL\\anaconda3\\envs\\llm\\Lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Batches: 100%|██████████| 169/169 [4:39:23<00:00, 99.19s/it]/s]\n",
      "Documents Processed: 10000 docs [4:39:26,  1.68s/ docs]           \n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 571/571 [00:00<00:00, 286kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 496M/496M [01:38<00:00, 5.06MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 79.0/79.0 [00:00<?, ?B/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.03MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 700kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 772/772 [00:00<?, ?B/s] \n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import EmbeddingRetriever, FARMReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "retriever = EmbeddingRetriever(document_store=document_store, embedding_model=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\", use_gpu=True)\n",
    "document_store.update_embeddings(retriever=retriever)\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)\n",
    "presidents_qa = ExtractiveQAPipeline(reader=reader, retriever=retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
