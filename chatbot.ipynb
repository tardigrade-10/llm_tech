{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "from env_config import Config\n",
    "openai.api_key = Config.OPENAI_API_KEY\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = []\n",
    "# AgentExecuter(agent, tools, llm).run() -> Chain().run(input) -> __call__(inputs) -> input_preparation (adding variables values and memory) -> _call (inputs) -> _take_next_step(enter agent execution loop) -> agent.plan(steps) (plan and generate intermediate steps, action or final result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import time\n",
      "\n",
      "class Agent:\n",
      "    def __init__(self, tools, llm, role_description, **kwargs):\n",
      "        self.tools = tools\n",
      "        self.llm = llm\n",
      "        self.role_description = role_description\n",
      "        self.kwargs = kwargs\n",
      "    \n",
      "    def run(self, input_query):\n",
      "        input_query = self._call(input_query)\n",
      "        return self._take_next_step(input_query)\n",
      "    \n",
      "    def __call__(self, inputs):\n",
      "        input_preparation = self._call(inputs)\n",
      "        return input_preparation\n",
      "    \n",
      "    def _call(self, inputs):\n",
      "        # Add any necessary variables and memory to the input\n",
      "        # For example, you could add a timestamp to inputs\n",
      "        inputs += \" | timestamp: \" + str(time.time())\n",
      "        \n",
      "        return inputs\n",
      "    \n",
      "    def _take_next_step(self, inputs):\n",
      "        # Perform the necessary steps to execute the task\n",
      "        steps = self.llm.generate_steps(inputs)\n",
      "        return self.plan(steps)\n",
      "    \n",
      "    def plan(self, steps):\n",
      "        # Generate the plan based on the steps\n",
      "        action = self.llm.generate_plan(steps)\n",
      "        return action\n",
      "\n",
      "# Example usage\n",
      "tools = ['google search']\n",
      "llm = LargeLanguageModel()\n",
      "role_description = 'Weather Agent'\n",
      "\n",
      "agent = Agent(tools, llm, role_description)\n",
      "\n",
      "input_query = \"what is the weather in new york today?\"\n",
      "response = agent.run(input_query)\n",
      "print(response)"
     ]
    }
   ],
   "source": [
    "\n",
    "system_text = \"You are a brilliant python coder and your job is to provide complete code for the user query\"\n",
    "user_text = '''\n",
    "An agent is something that takes a task as input, have access to tools (like google search for current affairs) and uses an LLM to generate plan and execute the given task. Below is the Sequence to build an Agent using Large language model in python. \n",
    "\n",
    "1. agent = Agent(tools, llm, role_description, **kwargs)\n",
    "2. agent.run(input = \"what is the weather in new york today?\")\n",
    "3. __call__(inputs) -> input_preparation (adding variables values and memory) \n",
    "4. _call (inputs) -> _take_next_step(enter agent execution loop)\n",
    "5. plan(steps) (plan and generate intermediate steps, action or final result)\n",
    "\n",
    "Create a single Agent class, that has all the required methods and works as an Agent. The Agent class will be initialized with llm, tools, and description of it's role. Then Agent.run function will tak an input query and will return the suitable response. All the main login will be in the .run function.\n",
    "\n",
    "Write the complete code for this. DO NOT worry about the length of the response.\n",
    "'''\n",
    "\n",
    "# with open('data/openaiembed.txt') as f:\n",
    "#     text = f.read()\n",
    "system_message = {\"role\":\"system\", \"content\": system_text}\n",
    "conversation.append(system_message)\n",
    "\n",
    "# user_input = \"DO you think we should keep both the classes separate or it'd work if we keep them as a single class?\"\n",
    "user_message = {\"role\":\"user\", \"content\": user_text}\n",
    "# print(user_message)\n",
    "conversation.append(user_message)\n",
    "\n",
    "bot_message = \"\"\n",
    "for token in openai.ChatCompletion.create(\n",
    "                        model = \"gpt-3.5-turbo-16k\",\n",
    "                        messages = conversation,\n",
    "                        stream = True\n",
    "                    ):\n",
    "    t = token[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
    "    print(t, end=\"\")\n",
    "    bot_message += t\n",
    "\n",
    "bot_message = {\"role\":\"assistant\", \"content\": bot_message}\n",
    "conversation.append(bot_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/final.txt', 'w') as f:\n",
    "    f.write(conversation[2][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 5, 6: 7, 7: 8}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {4:5, 6:7}\n",
    "\n",
    "d[7] = 8\n",
    "d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
