{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from env_config import Config\n",
    "\n",
    "openai.api_key = Config.OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Grand Canyon is a steep-sided canyon carved by the Colorado River in the state of Arizona, USA. It is approximately 277 miles long, up to 18 miles wide, and over a mile deep. The Grand Canyon is known for its stunning vistas, unique geological features, and rich cultural history. It is also home to a diverse range of plants and animals, many of which are found nowhere else on earth. The Grand Canyon is a popular tourist destination, attracting millions of visitors every year who come to hike, camp, and explore this remarkable natural wonder."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from env_config import Config\n",
    "\n",
    "openai.api_key = Config.OPENAI_API_KEY\n",
    "\n",
    "message = \"tell me seomthing about the grand canyan\"\n",
    "# for i in range(len(message)):\n",
    "\n",
    "for token in openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ],\n",
    "        stream = True,\n",
    "        n = 1\n",
    "        ):\n",
    "    print(token[\"choices\"][0][\"delta\"].get(\"content\", \"\"), end=\"\")\n",
    "\n",
    "# print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Paul Graham's mother had a stroke in the summer of 2012. As a result of the stroke, her balance was destroyed, and she had to be placed in a nursing home. However, Paul and his sister were determined to help her get out and return to her house. Paul frequently flew to Oregon to visit her, and during these visits, he had a lot of time to reflect.\\n\\nUnfortunately, his mother's cancer had returned. The cancer was the cause of the blood clot that led to her stroke. Sadly, she passed away on January 15, 2014. This was a difficult time for Paul and his family, as losing a loved one is always painful.\\n\\nFollowing his mother's passing, Paul decided to step back from his work at Y Combinator, the startup accelerator he co-founded. He wanted to take some time for himself and explore new interests. He began painting, which had always been a passion of his, and started writing essays again. However, he also realized that he missed working on programming languages, so he began working on a new version of Lisp called Bel.\\n\\nAfter some time, Paul returned to his work at Y Combinator, but in March 2014, he officially handed over the reins to Sam Altman, who became the new president. Paul continued to be involved as a partner, but his focus shifted as he explored new projects and endeavors.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1686742066,\n",
      "  \"id\": \"chatcmpl-7RIx8vkPWtmCpBw2KSoReaeLZdxiq\",\n",
      "  \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 283,\n",
      "    \"prompt_tokens\": 14969,\n",
      "    \"total_tokens\": 15252\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "system_message = \"You are a PaulGrahamGPT \\n Below is a informational summary about Paul Graham life \\n\"\n",
    "\n",
    "file_path = r\"C:\\Users\\DELL\\Documents\\python_projects\\llm_tech\\data\\paul_graham\\paul_graham_essay.txt\"\n",
    "\n",
    "with open(file_path) as f:\n",
    "    text = f.read()\n",
    "    system_message += text\n",
    "    system_message = system_message.split('Notes')[0]\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": \"When did Paul Graham's mother has the stroke? And what happened after that?\"}\n",
    "    ],\n",
    "    )\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7sV0Qftfn2TtsZIqLxyULi83K30tA\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1693223254,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"get_current_weather\",\n",
      "          \"arguments\": \"{\\n  \\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 82,\n",
      "    \"completion_tokens\": 18,\n",
      "    \"total_tokens\": 100\n",
      "  }\n",
      "}\n",
      "{\"location\": null, \"temperature\": \"72\", \"unit\": null, \"forecast\": [\"sunny\", \"windy\"]}\n",
      "{\n",
      "  \"id\": \"chatcmpl-7sV0StBINbwpZHJOqIUJ2F9VGFr4Y\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1693223256,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The current weather in Boston, MA is sunny and windy with a temperature of 72 degrees.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 70,\n",
      "    \"completion_tokens\": 19,\n",
      "    \"total_tokens\": 89\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)\n",
    "\n",
    "# Step 1, send model the user query and what functions it has access to\n",
    "def run_conversation():\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}],\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        function_call=\"auto\",\n",
    "    )\n",
    "    print(response)\n",
    "    message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    # Step 2, check if the model wants to call a function\n",
    "    if message.get(\"function_call\"):\n",
    "        function_name = message[\"function_call\"][\"name\"]\n",
    "\n",
    "        # Step 3, call the function\n",
    "        # Note: the JSON response from the model may not be valid JSON\n",
    "        function_response = get_current_weather(\n",
    "            location=message.get(\"location\"),\n",
    "            unit=message.get(\"unit\"),\n",
    "        )\n",
    "        print(function_response)\n",
    "\n",
    "        # Step 4, send model the info on the function call and function response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"What is the weather like in boston?\"},\n",
    "                message,\n",
    "                {\n",
    "                    \"role\": \"function\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        return second_response\n",
    "\n",
    "print(run_conversation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mserpapi\u001b[39;00m \u001b[39mimport\u001b[39;00m GoogleSearch\n\u001b[0;32m      3\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mengine\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mgoogle\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mq\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mweather in delhi today\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m----> 6\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mapi_key\u001b[39m\u001b[39m\"\u001b[39m: Config\u001b[39m.\u001b[39mSERP_API_KEY\n\u001b[0;32m      7\u001b[0m     }\n\u001b[0;32m      9\u001b[0m search \u001b[39m=\u001b[39m GoogleSearch(params)\n\u001b[0;32m     10\u001b[0m results \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39mget_dict()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Config' is not defined"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "\n",
    "params = {\n",
    "      \"engine\": \"google\",\n",
    "      \"q\": \"weather in delhi today\",\n",
    "      \"api_key\": Config.SERP_API_KEY\n",
    "    }\n",
    "\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "print(results.keys())\n",
    "\n",
    "# organic_results = results[\"answer_box\"]\n",
    "# print(organic_results.keys())\n",
    "\n",
    "# organic_results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def search_google(query):\n",
    "    params = {\n",
    "      \"engine\": \"google\",\n",
    "      \"q\": query,\n",
    "      \"api_key\": Config.SERP_API_KEY\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    organic_results = results[\"knowledge_graph\"]\n",
    "\n",
    "    return organic_results\n",
    "\n",
    "# Step 1, send model the user query and what functions it has access to\n",
    "def run_conversation():\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"What is the weather in the Delhi today?\"}],\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"search_google\",\n",
    "                \"description\": \"Use this function to Search on google to provide accurate answers for current affairs\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"query to search on google search engine\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"query\"],\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        function_call=\"auto\",\n",
    "    )\n",
    "    print(response)\n",
    "    message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    # Step 2, check if the model wants to call a function\n",
    "    if message.get(\"function_call\"):\n",
    "        function_name = message[\"function_call\"][\"name\"]\n",
    "        query = eval(message[\"function_call\"]['arguments'])\n",
    "\n",
    "        # Step 3, call the function\n",
    "        # Note: the JSON response from the model may not be valid JSON\n",
    "        function_response = search_google(query['query'])\n",
    "        print(function_response[:2])\n",
    "\n",
    "        # Step 4, send model the info on the function call and function response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"What is the weather forcast for Delhi today?\"},\n",
    "                message,\n",
    "                {\n",
    "                    \"role\": \"function\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response[:2],\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        return second_response\n",
    "\n",
    "print(run_conversation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7dEHBWqSmcDN2rEkrjirl7ZodPYj1\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1689584025,\n",
      "  \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"to_json\",\n",
      "          \"arguments\": \"{\\n  \\\"name\\\": \\\"Aria\\\",\\n  \\\"age\\\": \\\"25\\\",\\n  \\\"powers\\\": \\\"Fire Manipulation, Telekinesis, Invisibility\\\",\\n  \\\"history\\\": \\\"Aria grew up in a small village surrounded by mountains. At a young age, she discovered her ability to control fire and soon mastered the art of fire manipulation. She then developed telekinetic powers, allowing her to move objects with her mind. As she further honed her skills, she learned how to become invisible, blending seamlessly into her surroundings. Aria became a powerful and elusive warrior, using her unique abilities to protect her village from external threats.\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 105,\n",
      "    \"completion_tokens\": 136,\n",
      "    \"total_tokens\": 241\n",
      "  }\n",
      "}\n",
      "{\n",
      "    \"name\": \"Aria\",\n",
      "    \"age\": 25,\n",
      "    \"powers\": [\n",
      "        \"Fire Manipulation\",\n",
      "        \" Telekinesis\",\n",
      "        \" Invisibility\"\n",
      "    ],\n",
      "    \"history\": \"Aria grew up in a small village surrounded by mountains. At a young age, she discovered her ability to control fire and soon mastered the art of fire manipulation. She then developed telekinetic powers, allowing her to move objects with her mind. As she further honed her skills, she learned how to become invisible, blending seamlessly into her surroundings. Aria became a powerful and elusive warrior, using her unique abilities to protect her village from external threats.\"\n",
      "}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# json formatting with functions\n",
    "\n",
    "import openai\n",
    "import json\n",
    "\n",
    "def to_json(\n",
    "        name, age, powers, history\n",
    "        # **kwargs\n",
    "        ):\n",
    "    _json = {\n",
    "        'name': name,\n",
    "        'age': int(age),\n",
    "        'powers': powers.split(', '),\n",
    "        'history': history\n",
    "    }\n",
    "    _json = json.dumps(_json, indent=4)\n",
    "\n",
    "    return _json\n",
    "\n",
    "# Step 1, send model the user query and what functions it has access to\n",
    "def run_conversation():\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Generate a RPG game fake character profile and return in json\"}],\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"to_json\",\n",
    "                \"description\": \"use this function to covert character data to json format\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"description\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"description of the character: A quick and nimble fighter.\",\n",
    "                        },\n",
    "                        \"name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"name of the character\",\n",
    "                        },\n",
    "                        \"age\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"age of the character\",\n",
    "                        },\n",
    "                        \"weapons\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": 'one of [\"sword\", \"axe\", \"mace\", \"spear\", \"bow\", \"crossbow\"]',\n",
    "                        },\n",
    "                        \"class\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"\",\n",
    "                        },\n",
    "                        \"mantra\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"\",\n",
    "                        },\n",
    "                        \"strength\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"a number\",\n",
    "                        },\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"3 items\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [],\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "        function_call=\"auto\",\n",
    "    )\n",
    "    print(response)\n",
    "    message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    # Step 2, check if the model wants to call a function\n",
    "    if message.get(\"function_call\"):\n",
    "        # function_name = message[\"function_call\"][\"name\"]\n",
    "        args = eval(message[\"function_call\"]['arguments'])\n",
    "\n",
    "        # Step 3, call the function\n",
    "        # Note: the JSON response from the model may not be valid JSON\n",
    "        function_response = to_json(**args)\n",
    "        print(function_response)\n",
    "\n",
    "        # Step 4, send model the info on the function call and function response\n",
    "        # second_response = openai.ChatCompletion.create(\n",
    "        #     model=\"gpt-3.5-turbo-0613\",\n",
    "        #     messages=[\n",
    "        #         {\"role\": \"user\", \"content\": \"Generate a RPG game fake character profile and return in json\"},\n",
    "        #         message,\n",
    "        #         {\n",
    "        #             \"role\": \"function\",\n",
    "        #             \"name\": function_name,\n",
    "        #             \"content\": function_response,\n",
    "        #         },\n",
    "        #     ],\n",
    "        # )\n",
    "        # return second_response\n",
    "\n",
    "run_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
